{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Make test_images_output directory\n",
    "directories = []\n",
    "directories.append(\"./output_images/2_undistorted/\")\n",
    "directories.append(\"./output_images/3_thresholded_binary/\")\n",
    "directories.append(\"./output_images/4_birds_eye_view/\")\n",
    "directories.append(\"./output_images/5_lane_detected/\")\n",
    "directories.append(\"./output_images/7_cam_view/\")\n",
    "directories.append(\"./output_images/8_result/\")\n",
    "directories.append(\"./output_videos/\")\n",
    "directories.append(\"./output_images/1_calibration/\")\n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.15777942e+03   0.00000000e+00   6.67111052e+02]\n",
      " [  0.00000000e+00   1.15282305e+03   3.86129067e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "[[-0.24688831 -0.02372826 -0.00109843  0.00035105 -0.00259117]]\n"
     ]
    }
   ],
   "source": [
    "# prepare object points\n",
    "nx = 9#TODO: enter the number of inside corners in x\n",
    "ny = 6#llTODO: enter the number of inside corners in y\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "file_list = os.listdir(\"camera_cal/\")\n",
    "\n",
    "for file in file_list:\n",
    "    img = cv2.imread(\"camera_cal/\" + file)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    # If found, draw corners\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "        # Draw and display the corners\n",
    "        # cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "        # plt.imshow(img)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "for file in file_list:\n",
    "    img = cv2.imread(\"camera_cal/\" + file)\n",
    "    undistorted_example = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    mpimg.imsave(directories[7] + file, undistorted_example)\n",
    "\n",
    "print(mtx)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist):\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_binary_image(img, thresh_min=20, thresh_max=100, s_thresh_min=170, s_thresh_max=255):\n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    # Note: img is the undistorted image\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # Grayscale image\n",
    "    # NOTE: we already saw that standard grayscaling lost color information for the lane lines\n",
    "    # Explore gradients in other colors spaces / color channels to see what might work better\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "\n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birds_eye_view(img):\n",
    "    imshape = img.shape\n",
    "    src = np.float32([[250,imshape[0]],[610, 460], [740, 460], [1130,imshape[0]]])\n",
    "    dst = np.float32([[200, 700],[200, 0],[900, 0], [900, 700]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, gray.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        # cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        # (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        # cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        # (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    # out_img[lefty, leftx] = [255, 0, 0]\n",
    "    # out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    draw_points_left = (np.asarray([left_fitx, ploty]).T).astype(np.int32)\n",
    "    draw_points_right = (np.asarray([right_fitx, ploty]).T).astype(np.int32)\n",
    "    cv2.polylines(out_img, [draw_points_left], False, (255,0,0), 12)\n",
    "    cv2.polylines(out_img, [draw_points_right], False, (255,0,0), 12)\n",
    "    for i in ploty:\n",
    "        left_ = max(0, left_fit[0]*i**2 + left_fit[1]*i + left_fit[2])\n",
    "        right_ = min(right_fit[0]*i**2 + right_fit[1]*i + right_fit[2], binary_warped.shape[1]-1)\n",
    "        for x in range(int(left_), int(right_)):\n",
    "            out_img[int(i), x] = [0, 0, 255]\n",
    "    \n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    # plt.plot(left_fitx, ploty, color='yellow')\n",
    "    # plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return left_fit, right_fit, out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(left_fit_cr, right_fit_cr):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    curverad = (left_curverad + right_curverad) / 2.0\n",
    "    \n",
    "    left_vehicle_pix = left_fit_cr[0]*y_eval**2 + left_fit_cr[1]*y_eval + left_fit_cr[2]\n",
    "    right_vehicle_pix = right_fit_cr[0]*y_eval**2 + right_fit_cr[1]*y_eval + right_fit_cr[2]\n",
    "    center_vehicle_pix = (left_vehicle_pix + right_vehicle_pix) / 2.0\n",
    "    center_pix = (200 + 900) / 2.0\n",
    "    center_vehicle_m = (center_vehicle_pix - center_pix) * xm_per_pix \n",
    "    \n",
    "    return curverad, center_vehicle_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birds_eye_view_inv(original, detected):\n",
    "    imshape = img.shape\n",
    "    src = np.float32([[250,imshape[0]],[610, 460], [740, 460], [1130,imshape[0]]])\n",
    "    dst = np.float32([[200, 700],[200, 0],[900, 0], [900, 700]])\n",
    "    M = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped_inv = cv2.warpPerspective(detected, M, gray.shape[::-1], flags=cv2.INTER_LINEAR)\n",
    "    cam_view = cv2.addWeighted(original, 0.7, warped_inv, 1.0, 0.0)\n",
    "    return cam_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(img, curverad, center_vehicle_m):\n",
    "    left_right = \"left\" if (center_vehicle_m < 0) else \"right\"\n",
    "    curverad = round(curverad)\n",
    "    center_vehicle_m = round(center_vehicle_m, 2)\n",
    "    text1 = \"Radius of Curvature = %d(m)\" % (curverad)\n",
    "    text2 = \"Vehicle is %.2fm %s of center\" % (abs(center_vehicle_m), left_right)\n",
    "    cv2.putText(img, text1, (30,30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2)\n",
    "    cv2.putText(img, text2, (30,60), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pipeline by test_images and save results to output_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test_images_output directory\n",
    "file_list = os.listdir(\"test_images/\")\n",
    "\n",
    "for file in file_list:\n",
    "    img = mpimg.imread(\"test_images/\" + file)\n",
    "    \n",
    "    # step2\n",
    "    undistorted = undistort(img, mtx, dist)\n",
    "    # plt.imshow(cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB))\n",
    "    mpimg.imsave(directories[0] + file, cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # step3\n",
    "    combined_binary = threshold_binary_image(undistorted)\n",
    "    # Plotting thresholded images\n",
    "    # plt.imshow(combined_binary, cmap='gray')\n",
    "    mpimg.imsave(directories[1] + file, combined_binary, cmap=\"gray\")\n",
    "    \n",
    "    # stpe4\n",
    "    warped = birds_eye_view(combined_binary)\n",
    "    # cv2.line(img, (1130, imshape[0]), (740, 460), [255, 0, 0], 2)\n",
    "    # plt.imshow(warped, cmap=\"gray\")\n",
    "    # plt.imshow(img)\n",
    "    mpimg.imsave(directories[2] + file, warped, cmap=\"gray\")\n",
    "    \n",
    "    # step5\n",
    "    left_fitx, right_fitx, lane = fit_polynomial(warped)\n",
    "    # plt.imshow(lane)\n",
    "    mpimg.imsave(directories[3] + file, lane)\n",
    "    \n",
    "    # step6\n",
    "    curverad, center_vehicle_m = measure_curvature_real(left_fitx, right_fitx)\n",
    "    \n",
    "    # step7\n",
    "    cam_view = birds_eye_view_inv(img, lane)\n",
    "    # plt.imshow(cv2.cvtColor(cam_view, cv2.COLOR_BGR2RGB))\n",
    "    mpimg.imsave(directories[4] + file, cam_view)\n",
    "    \n",
    "    # step8\n",
    "    result = display_result(cam_view, curverad, center_vehicle_m)\n",
    "    mpimg.imsave(directories[5] + file, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    undistorted = undistort(img, mtx, dist)\n",
    "    combined_binary = threshold_binary_image(undistorted)\n",
    "    warped = birds_eye_view(combined_binary)\n",
    "    left_fitx, right_fitx, lane = fit_polynomial(warped)\n",
    "    curverad, center_vehicle_m = measure_curvature_real(left_fitx, right_fitx)\n",
    "    cam_view = birds_eye_view_inv(img, lane)\n",
    "    result = display_result(cam_view, curverad, center_vehicle_m)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imageio: 'ffmpeg.linux64' was not found on your computer; downloading it now.\n",
      "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg.linux64 (27.2 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 8192/28549024 bytes (0.0106496/28549024 bytes (0.4212992/28549024 bytes (0.7286720/28549024 bytes (1.0393216/28549024 bytes (1.4475136/28549024 bytes (1.7565248/28549024 bytes (2.0647168/28549024 bytes (2.3753664/28549024 bytes (2.6835584/28549024 bytes (2.9925696/28549024 bytes (3.21024000/28549024 bytes (3.6%1122304/28549024 bytes (3.9%1220608/28549024 bytes (4.3%1335296/28549024 bytes (4.7%1433600/28549024 bytes (5.0%1531904/28549024 bytes (5.4%1646592/28549024 bytes (5.8%1744896/28549024 bytes (6.1%1843200/28549024 bytes (6.5%1957888/28549024 bytes (6.9%2048000/28549024 bytes (7.2%2154496/28549024 bytes (7.5%2269184/28549024 bytes (7.9%2351104/28549024 bytes (8.2%2465792/28549024 bytes (8.6%2580480/28549024 bytes (9.0%2678784/28549024 bytes (9.4%2777088/28549024 bytes (9.7%2875392/28549024 bytes (10.12957312/28549024 bytes (10.43039232/28549024 bytes (10.63153920/28549024 bytes (11.03252224/28549024 bytes (11.43334144/28549024 bytes (11.73416064/28549024 bytes (12.03530752/28549024 bytes (12.43629056/28549024 bytes (12.73710976/28549024 bytes (13.03809280/28549024 bytes (13.33907584/28549024 bytes (13.74005888/28549024 bytes (14.04087808/28549024 bytes (14.34177920/28549024 bytes (14.64268032/28549024 bytes (14.94349952/28549024 bytes (15.24464640/28549024 bytes (15.64562944/28549024 bytes (16.04644864/28549024 bytes (16.34710400/28549024 bytes (16.54808704/28549024 bytes (16.84907008/28549024 bytes (17.24988928/28549024 bytes (17.55087232/28549024 bytes (17.85185536/28549024 bytes (18.25283840/28549024 bytes (18.55382144/28549024 bytes (18.95464064/28549024 bytes (19.15545984/28549024 bytes (19.45644288/28549024 bytes (19.85709824/28549024 bytes (20.05808128/28549024 bytes (20.35906432/28549024 bytes (20.75988352/28549024 bytes (21.06086656/28549024 bytes (21.36184960/28549024 bytes (21.76283264/28549024 bytes (22.06397952/28549024 bytes (22.46496256/28549024 bytes (22.86594560/28549024 bytes (23.16709248/28549024 bytes (23.56807552/28549024 bytes (23.86905856/28549024 bytes (24.26987776/28549024 bytes (24.57086080/28549024 bytes (24.87184384/28549024 bytes (25.27282688/28549024 bytes (25.57380992/28549024 bytes (25.97462912/28549024 bytes (26.17561216/28549024 bytes (26.57659520/28549024 bytes (26.87757824/28549024 bytes (27.27839744/28549024 bytes (27.57938048/28549024 bytes (27.88019968/28549024 bytes (28.18118272/28549024 bytes (28.48216576/28549024 bytes (28.88314880/28549024 bytes (29.18396800/28549024 bytes (29.48462336/28549024 bytes (29.68593408/28549024 bytes (30.18691712/28549024 bytes (30.48773632/28549024 bytes (30.78871936/28549024 bytes (31.18970240/28549024 bytes (31.49068544/28549024 bytes (31.89150464/28549024 bytes (32.19248768/28549024 bytes (32.49347072/28549024 bytes (32.79428992/28549024 bytes (33.09527296/28549024 bytes (33.49625600/28549024 bytes (33.79707520/28549024 bytes (34.09805824/28549024 bytes (34.39904128/28549024 bytes (34.710002432/28549024 bytes (35.0%10084352/28549024 bytes (35.3%10182656/28549024 bytes (35.7%10280960/28549024 bytes (36.0%10379264/28549024 bytes (36.4%10461184/28549024 bytes (36.6%10526720/28549024 bytes (36.9%10625024/28549024 bytes (37.2%10723328/28549024 bytes (37.6%10821632/28549024 bytes (37.9%10903552/28549024 bytes (38.2%11001856/28549024 bytes (38.5%11100160/28549024 bytes (38.9%11198464/28549024 bytes (39.2%11280384/28549024 bytes (39.5%11378688/28549024 bytes (39.9%11476992/28549024 bytes (40.2%11575296/28549024 bytes (40.5%11657216/28549024 bytes (40.8%11755520/28549024 bytes (41.2%11853824/28549024 bytes (41.5%11952128/28549024 bytes (41.9%12034048/28549024 bytes (42.2%12132352/28549024 bytes (42.5%12230656/28549024 bytes (42.8%12328960/28549024 bytes (43.2%12410880/28549024 bytes (43.5%12509184/28549024 bytes (43.8%12591104/28549024 bytes (44.1%12689408/28549024 bytes (44.4%12787712/28549024 bytes (44.8%12886016/28549024 bytes (45.1%12967936/28549024 bytes (45.4%13066240/28549024 bytes (45.8%13164544/28549024 bytes (46.1%13246464/28549024 bytes (46.4%13344768/28549024 bytes (46.7%13443072/28549024 bytes (47.1%13541376/28549024 bytes (47.4%13639680/28549024 bytes (47.8%13721600/28549024 bytes (48.1%13819904/28549024 bytes (48.4%13901824/28549024 bytes (48.7%14000128/28549024 bytes (49.0%14082048/28549024 bytes (49.3%14163968/28549024 bytes (49.6%14245888/28549024 bytes (49.9%14344192/28549024 bytes (50.2%14442496/28549024 bytes (50.6%14540800/28549024 bytes (50.9%14630912/28549024 bytes (51.2%14721024/28549024 bytes (51.6%14819328/28549024 bytes (51.9%14901248/28549024 bytes (52.2%14983168/28549024 bytes (52.5%15081472/28549024 bytes (52.8%15163392/28549024 bytes (53.1%15245312/28549024 bytes (53.4%15327232/28549024 bytes (53.7%15409152/28549024 bytes (54.0%15491072/28549024 bytes (54.3%15589376/28549024 bytes (54.6%15671296/28549024 bytes (54.9%15769600/28549024 bytes (55.2%15851520/28549024 bytes (55.5%15949824/28549024 bytes (55.9%16031744/28549024 bytes (56.2%16130048/28549024 bytes (56.5%16211968/28549024 bytes (56.8%16310272/28549024 bytes (57.1%16400384/28549024 bytes (57.4%16474112/28549024 bytes (57.7%16556032/28549024 bytes (58.0%16637952/28549024 bytes (58.3%16719872/28549024 bytes (58.6%16801792/28549024 bytes (58.9%16900096/28549024 bytes (59.2%16982016/28549024 bytes (59.5%17080320/28549024 bytes (59.8%17162240/28549024 bytes (60.1%17244160/28549024 bytes (60.4%17342464/28549024 bytes (60.7%17424384/28549024 bytes (61.0%17506304/28549024 bytes (61.3%17604608/28549024 bytes (61.7%17686528/28549024 bytes (62.0%17784832/28549024 bytes (62.3%17866752/28549024 bytes (62.6%17965056/28549024 bytes (62.9%18046976/28549024 bytes (63.2%18145280/28549024 bytes (63.6%18227200/28549024 bytes (63.8%18309120/28549024 bytes (64.1%18407424/28549024 bytes (64.5%18489344/28549024 bytes (64.8%18571264/28549024 bytes (65.1%18669568/28549024 bytes (65.4%18759680/28549024 bytes (65.7%18849792/28549024 bytes (66.0%18931712/28549024 bytes (66.3%19030016/28549024 bytes (66.7%19111936/28549024 bytes (66.9%19202048/28549024 bytes (67.3%19292160/28549024 bytes (67.6%19374080/28549024 bytes (67.9%19472384/28549024 bytes (68.2%19554304/28549024 bytes (68.5%19644416/28549024 bytes (68.8%19734528/28549024 bytes (69.1%19816448/28549024 bytes (69.4%19914752/28549024 bytes (69.8%19996672/28549024 bytes (70.0%20094976/28549024 bytes (70.4%20176896/28549024 bytes (70.7%20275200/28549024 bytes (71.0%20357120/28549024 bytes (71.3%20439040/28549024 bytes (71.6%20529152/28549024 bytes (71.9%20619264/28549024 bytes (72.2%20717568/28549024 bytes (72.6%20799488/28549024 bytes (72.9%20881408/28549024 bytes (73.1%20979712/28549024 bytes (73.5%21061632/28549024 bytes (73.8%21159936/28549024 bytes (74.1%21241856/28549024 bytes (74.4%21340160/28549024 bytes (74.7%21422080/28549024 bytes (75.0%21504000/28549024 bytes (75.3%21602304/28549024 bytes (75.7%21684224/28549024 bytes (76.0%21774336/28549024 bytes (76.3%21864448/28549024 bytes (76.6%21946368/28549024 bytes (76.9%22044672/28549024 bytes (77.2%22126592/28549024 bytes (77.5%22208512/28549024 bytes (77.8%22290432/28549024 bytes (78.1%22372352/28549024 bytes (78.4%22462464/28549024 bytes (78.7%22552576/28549024 bytes (79.0%22650880/28549024 bytes (79.3%22749184/28549024 bytes (79.7%22831104/28549024 bytes (80.0%22929408/28549024 bytes (80.3%22994944/28549024 bytes (80.5%23093248/28549024 bytes (80.9%23175168/28549024 bytes (81.2%23273472/28549024 bytes (81.5%23355392/28549024 bytes (81.8%23437312/28549024 bytes (82.1%23519232/28549024 bytes (82.4%23601152/28549024 bytes (82.7%23691264/28549024 bytes (83.0%23773184/28549024 bytes (83.3%23846912/28549024 bytes (83.5%23928832/28549024 bytes (83.8%24010752/28549024 bytes (84.1%24109056/28549024 bytes (84.4%24190976/28549024 bytes (84.7%24272896/28549024 bytes (85.0%24354816/28549024 bytes (85.3%24453120/28549024 bytes (85.7%24535040/28549024 bytes (85.9%24633344/28549024 bytes (86.3%24731648/28549024 bytes (86.6%24813568/28549024 bytes (86.9%24895488/28549024 bytes (87.2%24977408/28549024 bytes (87.5%25059328/28549024 bytes (87.8%25157632/28549024 bytes (88.1%25239552/28549024 bytes (88.4%25321472/28549024 bytes (88.7%25419776/28549024 bytes (89.0%25501696/28549024 bytes (89.3%25583616/28549024 bytes (89.6%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b25665536/28549024 bytes (89.9%25755648/28549024 bytes (90.2%25829376/28549024 bytes (90.5%25927680/28549024 bytes (90.8%26009600/28549024 bytes (91.1%26099712/28549024 bytes (91.4%26173440/28549024 bytes (91.7%26255360/28549024 bytes (92.0%26337280/28549024 bytes (92.3%26435584/28549024 bytes (92.6%26517504/28549024 bytes (92.9%26599424/28549024 bytes (93.2%26681344/28549024 bytes (93.5%26763264/28549024 bytes (93.7%26845184/28549024 bytes (94.0%26927104/28549024 bytes (94.3%27009024/28549024 bytes (94.6%27107328/28549024 bytes (95.0%27189248/28549024 bytes (95.2%27271168/28549024 bytes (95.5%27353088/28549024 bytes (95.8%27435008/28549024 bytes (96.1%27516928/28549024 bytes (96.4%27615232/28549024 bytes (96.7%27705344/28549024 bytes (97.0%27779072/28549024 bytes (97.3%27869184/28549024 bytes (97.6%27959296/28549024 bytes (97.9%28057600/28549024 bytes (98.3%28139520/28549024 bytes (98.6%28237824/28549024 bytes (98.9%28319744/28549024 bytes (99.2%28401664/28549024 bytes (99.5%28483584/28549024 bytes (99.8%28549024/28549024 bytes (100.0%)\n",
      "  Done\n",
      "File saved as /root/.imageio/ffmpeg/ffmpeg.linux64.\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pipeline by videos and save results to output_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/project_video.mp4\n",
      "[MoviePy] Writing video ./output_videos/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [12:02<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/project_video.mp4 \n",
      "\n",
      "CPU times: user 11min 58s, sys: 26.3 s, total: 12min 24s\n",
      "Wall time: 12min 2s\n"
     ]
    }
   ],
   "source": [
    "project_output = directories[6] + 'project_video.mp4'\n",
    "clip1 = VideoFileClip('project_video.mp4')\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./output_videos/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/challenge_video.mp4\n",
      "[MoviePy] Writing video ./output_videos/challenge_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [02:46<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/challenge_video.mp4 \n",
      "\n",
      "CPU times: user 2min 45s, sys: 10.3 s, total: 2min 55s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = directories[6] + 'challenge_video.mp4'\n",
    "clip2 = VideoFileClip('challenge_video.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./output_videos/challenge_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/harder_challenge_video.mp4\n",
      "[MoviePy] Writing video ./output_videos/harder_challenge_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [12:04<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/harder_challenge_video.mp4 \n",
      "\n",
      "CPU times: user 12min 2s, sys: 23.5 s, total: 12min 25s\n",
      "Wall time: 12min 5s\n"
     ]
    }
   ],
   "source": [
    "harder_challenge_output = directories[6] + 'harder_challenge_video.mp4'\n",
    "clip3 = VideoFileClip('harder_challenge_video.mp4')\n",
    "harder_challenge_clip = clip3.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time harder_challenge_clip.write_videofile(harder_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./output_videos/harder_challenge_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(harder_challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
